# Open Voice Agent Configuration Example
# Copy this file to .env and fill in your API keys

# LLM Provider (NVIDIA) - REQUIRED!
# Get your API key from: https://build.nvidia.com/
LLM_PROVIDER=nvidia  # or "huggingface"
NVIDIA_API_KEY=your_nvidia_api_key_here
NVIDIA_MODEL=meta/llama-3.1-8b-instruct

# Or use Hugging Face instead
# Get your token from: https://huggingface.co/settings/tokens
# LLM_PROVIDER=huggingface
# HF_TOKEN=your_huggingface_token_here
# HF_MODEL=meta-llama/Llama-3.1-8B-Instruct

# Voice Provider Options: "nvidia" or "gradium"
# NVIDIA Riva uses the same NVIDIA_API_KEY as the LLM provider
VOICE_PROVIDER=nvidia

# NVIDIA Voice Settings (default)
NVIDIA_VOICE_LANGUAGE=en-US
NVIDIA_VOICE_NAME=Magpie-Multilingual.EN-US.Aria

# NVIDIA TTS requires a self-hosted Riva TTS NIM
# See: https://docs.nvidia.com/nim/riva/tts/latest/getting-started.html
# Run the NIM container, then set the endpoint:
# NVIDIA_TTS_ENDPOINT=http://localhost:9000
# NVIDIA_TTS_API_TYPE=http  # or "grpc"

# Alternative: Gradium Voice Provider
# Uncomment these lines and comment out NVIDIA settings above to use Gradium
# VOICE_PROVIDER=gradium
# GRADIUM_API_KEY=your_gradium_api_key_here
# GRADIUM_VOICE_ID=YTpq7expH9539ERJ
# GRADIUM_REGION=us  # or "eu"

# Optional: Voice Settings (shared by both providers)
# SAMPLE_RATE_INPUT=24000
# SAMPLE_RATE_OUTPUT=48000
# VAD_THRESHOLD=0.5

# Optional: LLM Settings
# LLM_TEMPERATURE=0.7
# LLM_MAX_TOKENS=1024

# Optional: API Settings
# API_HOST=0.0.0.0
# API_PORT=8000
# API_WORKERS=1

# Optional: Environment Stage
# OVA_STAGE=prod  # or "dev"
