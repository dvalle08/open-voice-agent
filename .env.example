# LLM Provider Selection
LLM_PROVIDER=huggingface  # Options: nvidia, huggingface

# HuggingFace LLM Settings (for local inference)
HUGGINGFACE_MODEL_ID=Qwen/Qwen2.5-3B-Instruct
HUGGINGFACE_DEVICE=cuda  # Options: cuda, cpu, or leave empty for auto-detect

# NVIDIA LLM Settings (alternative provider)
NVIDIA_API_KEY=your_nvidia_api_key_here
NVIDIA_MODEL=meta/llama-3.1-8b-instruct

# HuggingFace Settings
HF_TOKEN=your_huggingface_token_here  # Get from: https://huggingface.co/settings/tokens

# Common LLM Parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1024

# Voice Provider Settings
VOICE_PROVIDER=nvidia
NVIDIA_VOICE_LANGUAGE=en-US
NVIDIA_VOICE_NAME=Magpie-Multilingual.EN-US.Aria

# LiveKit Settings
LIVEKIT_URL=wss://your-livekit-server.example.com
LIVEKIT_API_KEY=your_livekit_api_key_here
LIVEKIT_API_SECRET=your_livekit_api_secret_here
LIVEKIT_AGENT_NAME=open-voice-agent
LIVEKIT_NUM_IDLE_PROCESSES=2

# LiveKit Audio Input Configuration - OPTIMIZED FOR FALSE DETECTION FIX
LIVEKIT_SAMPLE_RATE=24000
LIVEKIT_NUM_CHANNELS=1
LIVEKIT_FRAME_SIZE_MS=20  # Smaller = faster VAD response, less latency
LIVEKIT_PRE_CONNECT_AUDIO=true
LIVEKIT_PRE_CONNECT_TIMEOUT=3.0

# Voice Activity Detection (VAD) Configuration - OPTIMIZED FOR FALSE DETECTION FIX
VAD_MIN_SPEECH_DURATION=0.25  # Require 250ms of speech before activation
VAD_MIN_SILENCE_DURATION=0.5  # Require 500ms of silence before deactivation
VAD_THRESHOLD=0.6  # Higher = less sensitive to noise (0.5 is default)

