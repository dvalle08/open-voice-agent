
LLM_PROVIDER=nvidia  # or "huggingface"
NVIDIA_API_KEY=your_nvidia_api_key_here
NVIDIA_MODEL=meta/llama-3.1-8b-instruct

# Uncomment the following block when using HuggingFace instead of NVIDIA
# LLM_PROVIDER=huggingface
# HF_MODEL=microsoft/DialoGPT-medium
# HF_TOKEN=your_huggingface_token_here  # Get from: https://huggingface.co/settings/tokens
# HF_USE_INFERENCE_API=false  # true to use the Hugging Face Inference API, false to run locally
# HF_TRUST_REMOTE_CODE=false  # Enable when the repo requires custom model/tokenizer code
# HF_USE_FAST_TOKENIZER=false  # Set to true when you need the fast tokenizer; disable to avoid legacy conversion issues


# Voice Provider Options
# NVIDIA API uses the same NVIDIA_API_KEY as the LLM provider
VOICE_PROVIDER=nvidia

# NVIDIA Voice Settings (default)
NVIDIA_VOICE_LANGUAGE=en-US
NVIDIA_VOICE_NAME=Magpie-Multilingual.EN-US.Aria

# NVIDIA TTS requires an endpoint from build.nvidia.com
# Get your TTS endpoint from: https://build.nvidia.com/
NVIDIA_TTS_ENDPOINT=https://your-tts-endpoint-here
